[2022-07-04 05:20:28,920] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: mytrigger.test_trigger_dagrun manual__2022-07-04T05:20:27.787265+00:00 [queued]>
[2022-07-04 05:20:28,927] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: mytrigger.test_trigger_dagrun manual__2022-07-04T05:20:27.787265+00:00 [queued]>
[2022-07-04 05:20:28,927] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-07-04 05:20:28,927] {taskinstance.py:1250} INFO - Starting attempt 1 of 1
[2022-07-04 05:20:28,927] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-07-04 05:20:28,934] {taskinstance.py:1270} INFO - Executing <Task(TriggerDagRunOperator): test_trigger_dagrun> on 2022-07-04 05:20:27.787265+00:00
[2022-07-04 05:20:28,937] {standard_task_runner.py:52} INFO - Started process 179 to run task
[2022-07-04 05:20:28,940] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'mytrigger', 'test_trigger_dagrun', 'manual__2022-07-04T05:20:27.787265+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/demo.py', '--cfg-path', '/tmp/tmpcimpfyln', '--error-file', '/tmp/tmppjc_q5tm']
[2022-07-04 05:20:28,940] {standard_task_runner.py:80} INFO - Job 16: Subtask test_trigger_dagrun
[2022-07-04 05:20:28,976] {logging_mixin.py:109} INFO - Running <TaskInstance: mytrigger.test_trigger_dagrun manual__2022-07-04T05:20:27.787265+00:00 [running]> on host 1936d03cc531
[2022-07-04 05:20:29,010] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mytrigger
AIRFLOW_CTX_TASK_ID=test_trigger_dagrun
AIRFLOW_CTX_EXECUTION_DATE=2022-07-04T05:20:27.787265+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-04T05:20:27.787265+00:00
[2022-07-04 05:20:29,706] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/api/common/trigger_dag.py:90: DeprecationWarning: Calling `DAG.create_dagrun()` without an explicit data interval is deprecated
  dag_hash=dag_bag.dags_hash.get(dag_id),

[2022-07-04 05:20:29,715] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dag_run_dag_id_run_id_key"
DETAIL:  Key (dag_id, run_id)=(mytrigger, manual__2022-07-04T05:20:29.011201+00:00) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/trigger_dagrun.py", line 149, in execute
    replace_microseconds=False,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api/common/trigger_dag.py", line 124, in trigger_dag
    replace_microseconds=replace_microseconds,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api/common/trigger_dag.py", line 90, in _trigger_dag
    dag_hash=dag_bag.dags_hash.get(dag_id),
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2361, in create_dagrun
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_run_id_key"
DETAIL:  Key (dag_id, run_id)=(mytrigger, manual__2022-07-04T05:20:29.011201+00:00) already exists.

[SQL: INSERT INTO dag_run (dag_id, queued_at, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, data_interval_start, data_interval_end, last_scheduling_decision, dag_hash) VALUES (%(dag_id)s, %(queued_at)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(data_interval_start)s, %(data_interval_end)s, %(last_scheduling_decision)s, %(dag_hash)s) RETURNING dag_run.id]
[parameters: {'dag_id': 'mytrigger', 'queued_at': datetime.datetime(2022, 7, 4, 5, 20, 29, 707368, tzinfo=Timezone('UTC')), 'execution_date': DateTime(2022, 7, 4, 5, 20, 29, 11201, tzinfo=Timezone('UTC')), 'start_date': None, 'end_date': None, 'state': <TaskInstanceState.QUEUED: 'queued'>, 'run_id': 'manual__2022-07-04T05:20:29.011201+00:00', 'creating_job_id': None, 'external_trigger': True, 'run_type': <DagRunType.MANUAL: 'manual'>, 'conf': <psycopg2.extensions.Binary object at 0x7efe997ecc00>, 'data_interval_start': DateTime(2022, 7, 4, 5, 20, 29, 11201, tzinfo=Timezone('UTC')), 'data_interval_end': DateTime(2022, 7, 4, 5, 20, 29, 11201, tzinfo=Timezone('UTC')), 'last_scheduling_decision': None, 'dag_hash': '8d0bbbecd9f255a12cda544c0ebbf68b'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-07-04 05:20:29,726] {taskinstance.py:1288} INFO - Marking task as FAILED. dag_id=mytrigger, task_id=test_trigger_dagrun, execution_date=20220704T052027, start_date=20220704T052028, end_date=20220704T052029
[2022-07-04 05:20:29,735] {standard_task_runner.py:98} ERROR - Failed to execute job 16 for task test_trigger_dagrun ((psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_run_id_key"
DETAIL:  Key (dag_id, run_id)=(mytrigger, manual__2022-07-04T05:20:29.011201+00:00) already exists.

[SQL: INSERT INTO dag_run (dag_id, queued_at, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, data_interval_start, data_interval_end, last_scheduling_decision, dag_hash) VALUES (%(dag_id)s, %(queued_at)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(data_interval_start)s, %(data_interval_end)s, %(last_scheduling_decision)s, %(dag_hash)s) RETURNING dag_run.id]
[parameters: {'dag_id': 'mytrigger', 'queued_at': datetime.datetime(2022, 7, 4, 5, 20, 29, 707368, tzinfo=Timezone('UTC')), 'execution_date': DateTime(2022, 7, 4, 5, 20, 29, 11201, tzinfo=Timezone('UTC')), 'start_date': None, 'end_date': None, 'state': <TaskInstanceState.QUEUED: 'queued'>, 'run_id': 'manual__2022-07-04T05:20:29.011201+00:00', 'creating_job_id': None, 'external_trigger': True, 'run_type': <DagRunType.MANUAL: 'manual'>, 'conf': <psycopg2.extensions.Binary object at 0x7efe997ecc00>, 'data_interval_start': DateTime(2022, 7, 4, 5, 20, 29, 11201, tzinfo=Timezone('UTC')), 'data_interval_end': DateTime(2022, 7, 4, 5, 20, 29, 11201, tzinfo=Timezone('UTC')), 'last_scheduling_decision': None, 'dag_hash': '8d0bbbecd9f255a12cda544c0ebbf68b'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj); 179)
[2022-07-04 05:20:29,753] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-07-04 05:20:29,771] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
